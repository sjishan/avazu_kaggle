{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = {\n",
    "    'id': np.str, 'click': np.bool, 'hour': np.str,\n",
    "    'C1': np.uint16, 'banner_pos': np.uint16,\n",
    "    'site_id': np.str, 'site_domain': np.str, 'site_category': np.str,\n",
    "    'app_id': np.str, 'app_domain': np.str, 'app_category': np.str,\n",
    "    'device_id': np.str, 'device_ip': np.str, 'device_model': np.str, 'device_type': np.uint16, \n",
    "    'device_conn_type': np.uint16,\n",
    "    'C14': np.uint16, 'C15': np.uint16, 'C16': np.uint16, 'C17': np.uint16, \n",
    "    'C18': np.uint16, 'C19': np.uint16, 'C20': np.uint32, 'C21': np.uint16    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "\n",
    "row_count = 40428968 #row count taken without opening the file,  wc -l train.csv\n",
    "\n",
    "row_limit = 250000 #limit the number of rows\n",
    "\n",
    "skip_first = 30000000\n",
    "\n",
    "#selecting the rows to be skipped\n",
    "skip = [i for i in xrange(skip_first)] + sorted(random.sample(xrange(skip_first, row_count), row_count - (skip_first + row_limit)))  \n",
    "\n",
    "skip.remove(0)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/train.csv', \n",
    "                   delimiter = ',', \n",
    "                   skiprows = skip, \n",
    "                   dtype = dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling the Class Imbalance Problem through downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df[df.click == True], df[df.click == False].sample(df[df.click == True].shape[0])])\n",
    "df = df.sort_values('hour', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample size: 79482\n"
     ]
    }
   ],
   "source": [
    "print \"New sample size: \" + str(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('data/labels', df['click'].values) #saving lavels to the disk. df will be re-used to save the memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the importance of the hidden columns by feature ranking through RFE and ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_cols = ['C1', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination\n",
    "- Recursively remove each features builds a model using the remaining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Ranking: [('C1', 2), ('C14', 1), ('C15', 5), ('C16', 6), ('C17', 1), ('C18', 7), ('C19', 3), ('C20', 1), ('C21', 4)]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(df[c_cols], df['click'])\n",
    "print(\"Feature Ranking: %s\") % zip(c_cols,fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier\n",
    "- Light-weight random forest used for getting the Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance: [('C1', 0.037572626869539764), ('C14', 0.21028507596634261), ('C15', 0.01448254700272102), ('C16', 0.062991921662398725), ('C17', 0.098639002812250715), ('C18', 0.19876921205504505), ('C19', 0.10077944509939389), ('C20', 0.16427790000997006), ('C21', 0.11220226852233814)]\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier()\n",
    "model.fit(df[c_cols], df['click'])\n",
    "print(\"Feature Importance: %s\") % zip(c_cols,model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the Column Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_columns = ['banner_pos', 'site_category', 'app_category', 'site_domain', 'app_domain', \n",
    "                    'device_model', 'device_type', 'device_conn_type', 'C14', 'C19', 'C20']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding of the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(df, features_columns):\n",
    "    df = pd.get_dummies(df, columns=features_columns, sparse=True)\n",
    "    return df.values # Changing to numpy to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = one_hot_encoding(df[selected_columns], selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: (79482L, 5308L)\n"
     ]
    }
   ],
   "source": [
    "print \"Dimensions: \" + str(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principle Component Analysis to reduce the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components= 300)\n",
    "df = pca.fit(df.T)\n",
    "np.save('data/features_pca', df.components_) #saving features to the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
